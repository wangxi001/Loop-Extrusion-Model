{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybedtools import BedTool, example_bedtool\n",
    "from math import pow, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# generate CTCF pair from CTCF peak list #\n",
    "##########################################\n",
    "def peakToPair(df_peak, f_out):\n",
    "    print(datetime.now())\n",
    "    #df_peak = pd.read_csv(f_in,sep='\\t',header=None)\n",
    "    ncol = len(df_peak.columns)\n",
    "    df_peak.columns = range(len(df_peak.columns))\n",
    "    df_peak['tmp_index'] = df_peak.index\n",
    "    dic_peak = df_peak.set_index('tmp_index').T.to_dict()\n",
    "\n",
    "    pbt_peak = BedTool.from_dataframe(df_peak).slop(b=500000,genome=\"hg38\")\n",
    "    df_peak_intersect = pbt_peak.intersect(pbt_peak,wo=True).to_dataframe(disable_auto_names=True, header=None)\n",
    "    df_peak_intersect.columns = range(len(df_peak_intersect.columns))\n",
    "    df_peak_intersect = df_peak_intersect[df_peak_intersect[ncol]<df_peak_intersect[ncol*2+1]].reset_index()\n",
    "\n",
    "    df_peak_list1 = pd.DataFrame(df_peak_intersect[ncol].map(dic_peak).tolist())\n",
    "    df_peak_list2 = pd.DataFrame(df_peak_intersect[ncol*2+1].map(dic_peak).tolist())\n",
    "    df_peak_list1.columns = range(len(df_peak_list1.columns))\n",
    "    df_peak_list2.columns = range(len(df_peak_list2.columns))\n",
    "\n",
    "    df_peak_pair = pd.concat([df_peak_list1.iloc[:,0:3],df_peak_list2.iloc[:,0:3],df_peak_list1.iloc[:,3:ncol],df_peak_list2.iloc[:,3:ncol]],axis=1)\n",
    "    print(datetime.now())\n",
    "    if(f_out==0):\n",
    "        return df_peak_pair\n",
    "    else:\n",
    "        df_peak_pair.to_csv(f_out,sep='\\t',index=False,header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peakToPair('CTCF_cohesin_consensus_20k_300_hg38.bed','CTCF_300_pair_1Mb_hg38.bedpe')\n",
    "peakToPair('CTCF_cohesin_consensus_20k_500_hg38.bed','CTCF_500_pair_1Mb_hg38.bedpe')\n",
    "peakToPair('CTCF_cohesin_consensus_20k_1k_hg38.bed','CTCF_1k_pair_1Mb_hg38.bedpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# identify CTCF motif orientation #\n",
    "###################################\n",
    "\n",
    "peakname = 'CTCF_cohesin_consensus_20k_300_hg38'\n",
    "\n",
    "#os.system('python2 ~/work/scripts/fetchseqs.py '+peakname+'.bed '+peakname+'.fa -d ~/work/genomes/hg38')\n",
    "#os.system('storm -m -s '+peakname+'.fa ~/Desktop/software/CTCF.mat > '+peakname+'.CTCFmotif.txt')\n",
    "\n",
    "df_in = pd.read_csv(peakname+'.CTCFmotif.txt',sep=' ',header=None,names=range(9),usecols=[0,3,7,8])\n",
    "df_motif = df_in[df_in[0]=='BS'][[3,7,8]].replace(';', '',regex=True).drop_duplicates()\n",
    "df_motif.columns = ['index','strand','score']\n",
    "df_motif['score'] = df_motif['score'].astype(int)\n",
    "#df_motif['score'] = df_motif['score'].round(3)\n",
    "df_peak = pd.read_csv(peakname+'.bed',sep='\\t',header=None)\n",
    "df_peak['index'] = df_peak[0]+':'+(df_peak[1]+1).astype(str)+'-'+df_peak[2].astype(str)\n",
    "\n",
    "dic_motif = df_motif.set_index('index').T.to_dict()\n",
    "df_peak[['score','strand']] = pd.DataFrame(df_peak['index'].map(dic_motif).tolist())\n",
    "\n",
    "df_peak['index'] = df_peak.index\n",
    "df_peak.to_csv(peakname+'.CTCFmotif.bed',sep='\\t',index=False,header=False)\n",
    "'''\n",
    "df_peak.columns = ['chr','s','e','index','score','strand']\n",
    "df_peak['strand'] = df_peak['strand'].replace(to_replace=['p', 'n'], value=[1, -1])\n",
    "\n",
    "df_in = df_peak[:]\n",
    "df_peak_pair = peakToPair(df_in,0)\n",
    "df_peak_pair.columns = ['chr1','s1','e1','chr2','s2','e2','index1','score1','strand1','index2','score2','strand2']\n",
    "df_peak_pair[['chr1','s1','e1','chr2','s2','e2','score1','strand1','score2','strand2']].to_csv('CTCF_300_pair_1Mb_hg38.CTCFmotif.bedpe',sep='\\t',index=False,header=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCF_binding_intensity(bw_file,bed_file,cell):\n",
    "    peak_size = '300'\n",
    "    df_peak = pd.read_csv('CTCF_cohesin_consensus_20k_'+peak_size+'_hg38.bed',sep='\\t',header=None)\n",
    "    df_macs = pd.read_csv('/data/mbeer3/data/'+bed_file,sep='\\t',header=None)\n",
    "\n",
    "    df_summit = pd.DataFrame({'chr': df_macs[0], \\\n",
    "                          's': df_macs[1]+df_macs[9], \\\n",
    "                          'e': df_macs[1]+df_macs[9]+1, \\\n",
    "                          'strand': '.', \\\n",
    "                          'score': df_macs[6]}).sort_values(['chr','s'])\n",
    "\n",
    "    pbt_peak = BedTool.from_dataframe(df_peak)\n",
    "    pbt_summit = BedTool.from_dataframe(df_summit)\n",
    "    df_peak_summit = pbt_peak.map(pbt_summit,o='max').to_dataframe(disable_auto_names=True, header=None).replace('.',0)\n",
    "    df_peak_summit[3].to_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_MACSscore.txt',sep='\\t',index=False,header=False)\n",
    "    \n",
    "    os.system('bigWigAverageOverBed /data/mbeer3/data/'+bw_file+' CTCF_cohesin_consensus_20k_'+peak_size+'_hg38.CTCFmotif.bed '+'ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_readcount.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LEmodel(peak_size, bw_file, cell, kd_scale, w, CTCF_BI):\n",
    "\n",
    "    #os.system('bigWigAverageOverBed /data/mbeer3/data/'+bw_file+' CTCF_cohesin_consensus_20k_'+peak_size+'_hg38.CTCFmotif.bed '+'ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_readcount.txt')\n",
    "    if(CTCF_BI == 'readcount'):\n",
    "        df_ctcf_chip = pd.read_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_readcount.txt',sep='\\t',header=None,usecols=[0,3])\n",
    "        df_ctcf_chip.columns = ['id','count']\n",
    "        df_ctcf_chip = df_ctcf_chip.sort_values('id').reset_index()\n",
    "    else:\n",
    "        df_ctcf_chip = pd.read_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_MACSscore.txt',sep='\\t',header=None)\n",
    "        df_ctcf_chip.columns = ['count']\n",
    "        \n",
    "    kd = df_ctcf_chip['count'].mean()*kd_scale\n",
    "\n",
    "    df_peak = pd.read_csv('CTCF_cohesin_consensus_20k_'+peak_size+'_hg38.CTCFmotif.bed',sep='\\t',header=None)\n",
    "    df_peak.columns = ['chr','s','e','index','score','strand']\n",
    "    df_peak['strand'] = df_peak['strand'].replace(to_replace=['p', 'n'], value=[1, -1])\n",
    "    df_peak['index'] = df_peak.index+1\n",
    "    df_peak['score'][df_peak['score'] < 0] = 0\n",
    "    df_peak['p_i'] = df_ctcf_chip['count']/(df_ctcf_chip['count']+kd)\n",
    "    \n",
    "    df_in = df_peak[:]\n",
    "    df_peak_pair = peakToPair(df_in,0)\n",
    "    df_peak_pair.columns = ['chr1','s1','e1','chr2','s2','e2','index1','score1','strand1','p_i','index2','score2','strand2','p_j']\n",
    "    df_peak_pair['p_ij'] = df_peak_pair['p_i']*df_peak_pair['p_j']\n",
    "    df_peak_pair['ori'] = np.power(w,(df_peak_pair['strand1']-df_peak_pair['strand2']-2)/2)\n",
    "\n",
    "    print(datetime.now())\n",
    "    df_peak_pair['lc'] = df_peak_pair.apply(lambda x: np.prod([1-df_peak.loc[i,'p_i'] for i in range(x['index1'],x['index2']-1)]), axis=1)\n",
    "    df_peak_pair['le_prediction'] = df_peak_pair['p_ij']*df_peak_pair['ori']*df_peak_pair['lc']\n",
    "    print(datetime.now())\n",
    "    \n",
    "    df_peak_pair[['p_ij','ori','lc','le_prediction']].to_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_LEmodel.'+CTCF_BI+'.txt',index=False,header=False,sep='\\t')\n",
    "    #os.system('rm ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_readcount.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEmodel('300', 'ENCFF541CSJ.bigWig', 'CTCF_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell = pd.read_csv('ENCODE_CTCF_list.txt',sep='\\t',header=None)\n",
    "sample_name = open('sample_name.txt').readline().split()\n",
    "cell_list = pd.DataFrame(pd.Series(sample_name).str.split('_',1, expand=True))[0].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#run LE model for all cell line#\n",
    "############################\n",
    "\n",
    "for i,x in df_cell.iterrows():\n",
    "    if(x[5] not in cell_list):\n",
    "        continue\n",
    "    #if(not os.path.isfile('ENCODE_'+x[0]+'_300_pair_1Mb_hg38_readcount.txt')):\n",
    "        #f_out.write('CTCF_binding_intensity(\\''+x[3]+'\\',\\''+x[1]+'\\',\\''+x[0]+'\\')\\n')\n",
    "        #CTCF_binding_intensity(x[3],x[1],x[0])\n",
    "    f_out = open('qf1','w')\n",
    "    f_out.write('#!/bin/bash\\n')\n",
    "    f_out.write('#SBATCH --time=48:0:0\\n')\n",
    "    f_out.write('#SBATCH --mem=12G\\n\\n')\n",
    "\n",
    "    f_out.write('python LEmodel_predict.py 300 '+x[3]+' '+x[0]+' 6.0 3.0 MACSscore'+'\\n')\n",
    "    f_out.close()\n",
    "    os.system('sbatch qf1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#run LE model grid search for all cell line#\n",
    "############################################\n",
    "x = df_cell[17:18].values.tolist()[0]\n",
    "for kd in range(2,22,2):\n",
    "    for w in range(7,25,2):\n",
    "        f_out = open('qf1','w')\n",
    "        f_out.write('#!/bin/bash\\n')\n",
    "        f_out.write('#SBATCH --time=48:0:0\\n')\n",
    "        f_out.write('#SBATCH --mem=12G\\n\\n')\n",
    "        #print('python LEmodel_predict.py 300 '+x[3]+' '+x[0]+' '+str(kd/2)+' '+str(w/5)+' '+'readcount'+'\\n')\n",
    "        f_out.write('python LEmodel_predict.py 300 '+x[3]+' '+x[0]+' '+str(kd/2)+' '+str(w/5)+' '+'readcount'+'\\n')\n",
    "        f_out.write('python LEmodel_predict.py 300 '+x[3]+' '+x[0]+' '+str(kd/2)+' '+str(w/5)+' '+'MACSscore'+'\\n')\n",
    "        f_out.close()\n",
    "        os.system('sbatch qf1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "#merge read count of all sample#\n",
    "################################\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "peak_size = '300'\n",
    "for i,x in df_cell.iterrows():\n",
    "    cell = x[0]\n",
    "    df_in = pd.read_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_readcount.txt',sep='\\t',header=None)\n",
    "    df_out[x[0]] = df_in[3].round(1)\n",
    "\n",
    "df_out.to_csv('all_ENCODE_CTCF_'+peak_size+'_pair_1Mb_hg38_readcount.txt',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#merge LE model prediction of all sample#\n",
    "#########################################\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "peak_size = '300'\n",
    "for i,x in df_cell.iterrows():\n",
    "    cell = x[0]\n",
    "    #print(x[5])\n",
    "    #if(x[5] not in cell_list):\n",
    "    #    os.system('rm ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_LEmodel.txt')\n",
    "    \n",
    "    if(x[5] in cell_list):\n",
    "        df_in = pd.read_csv('ENCODE_'+cell+'_'+peak_size+'_pair_1Mb_hg38_LEmodel_6.0_3.0_readcount.txt',sep='\\t',header=None)\n",
    "        #print('LE_'+x[5]+'_'+x[0].split('_')[1])\n",
    "        df_out['LE_'+x[5]+'_'+x[0].split('_')[1]] = (df_in[0]*df_in[2]*100).round(6)\n",
    "    \n",
    "#df_out.to_csv('all_ENCODE_CTCF_'+peak_size+'_pair_1Mb_hg38_LEmodel.txt',index=False,sep='\\t')\n",
    "#df_out.to_csv('all_ChIAPET_CTCF_'+peak_size+'_pair_1Mb_hg38_LEmodel.txt',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('all_ChIAPET_CTCF_'+peak_size+'_pair_1Mb_hg38_LEmodel_6.0_3.0_readcount.txt',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# sort bam, bam2bedpe, remove duplicate #\n",
    "#########################################\n",
    "\n",
    "def removeDuplicate(prefix_readpair):\n",
    "\n",
    "    print(datetime.now())\n",
    "    #prefix_readpair = 'K562_CTCF_1'\n",
    "    os.system('samtools sort -n -o '+prefix_readpair+'_hg38_sorted.bam --threads 4 '+prefix_readpair+'_hg38.bam')\n",
    "    print('Finish sorting bam')\n",
    "    os.system('bedtools bamtobed -i '+prefix_readpair+'_hg38_sorted.bam -bedpe > '+prefix_readpair+'_hg38_sorted.bedpe')\n",
    "    print('Finish bam to bedpe')\n",
    "    \n",
    "    df = pd.read_csv(prefix_readpair+'_hg38_sorted.bedpe',sep='\\t',header=None,usecols=[0,1,2,3,4,5])\n",
    "    df = df[df[0]==df[3]]\n",
    "    df_sort = df.sort_values([0,1,3,4])\n",
    "    print('Finish sorting bedpe')\n",
    "    \n",
    "    df_uniq = df_sort.drop_duplicates()\n",
    "    df_uniq.to_csv(prefix_readpair+'_hg38_sorted.rmdup.intra.bedpe',sep='\\t',index=False,header=False)\n",
    "    print('Finish removing duplicate')\n",
    "    \n",
    "    os.system('rm '+prefix_readpair+'_hg38_sorted.bam')\n",
    "    os.system('rm '+prefix_readpair+'_hg38_sorted.bedpe')\n",
    "    print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeDuplicate('K562_CTCF_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_list = list(os.popen('ls *_CTCF_r*bam|sed \\'s/hg38.bam//g\\''))\n",
    "prefix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(prefix_list)):\n",
    "    prefix = prefix_list[i].strip('\\n')\n",
    "    ofile = open('qsub_'+prefix,'w')\n",
    "    ofile.write('#!/bin/bash\\n')\n",
    "    ofile.write('#SBATCH --time=48:0:0\\n')\n",
    "    ofile.write('#SBATCH --mem=36G\\n')\n",
    "    ofile.write('python3 process_bam.py '+prefix+'\\n')\n",
    "    ofile.write('')\n",
    "    ofile.close()\n",
    "    #os.system(\"sbatch qLASSOnf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# map PET read to loop list #\n",
    "#############################\n",
    "\n",
    "def countPET(prefix_peakpair,prefix_readpair):\n",
    "    #prefix_peakpair = 'CTCF_300_pair_1Mb_hg38'\n",
    "    #prefix_readpair = 'K562_CTCF_1'\n",
    "    print(datetime.now())\n",
    "    print(prefix_peakpair,prefix_readpair)\n",
    "    \n",
    "    df_ctcfpair = pd.read_csv(prefix_peakpair+'.bedpe',sep='\\t',header=None)\n",
    "    df_ctcfpair['index'] = df_ctcfpair.index\n",
    "    df_readpair = pd.read_csv(prefix_readpair+'_hg38_sorted.rmdup.intra.bedpe',sep='\\t',header=None)\n",
    "    print('Finish reading bedpe')\n",
    "    \n",
    "    pbt_uniq = BedTool.from_dataframe(df_readpair)\n",
    "    pbt_ctcfpair = BedTool.from_dataframe(df_ctcfpair)\n",
    "    pbt_intersect = pbt_ctcfpair.pair_to_pair(pbt_uniq)\n",
    "    print('Finish intersecting bedpe')\n",
    "    \n",
    "    df_intersect = pbt_intersect.to_dataframe(disable_auto_names=True, header=None)\n",
    "    df_ctcfpair['PET'] = df_ctcfpair['index'].map(df_intersect[6].value_counts()).fillna(0).astype(int)\n",
    "    df_ctcfpair['PET'].to_csv(prefix_peakpair+'_PETcount_'+prefix_readpair+'.txt',sep='\\t',index=False,header=False)\n",
    "    print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countPET('CTCF_300_pair_1Mb_hg38','K562_CTCF_1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
